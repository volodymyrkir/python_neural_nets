{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6bc0fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d99d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_transforms = [\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "]\n",
    "\n",
    "augmentation_transforms = [\n",
    "    transforms.RandomRotation(45),\n",
    "    v2.RandomResizedCrop(size=(28, 28), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "]\n",
    "\n",
    "train_indices = torch.randperm(60000)[:2000]\n",
    "train_dataset = torch.utils.data.Subset(torchvision.datasets.FashionMNIST(\n",
    "        root='./data', train=True, download=True, \n",
    "        transform=transforms.Compose(preprocess_transforms + augmentation_transforms)\n",
    "    ),\n",
    "    train_indices\n",
    ")\n",
    "\n",
    "test_indices = torch.randperm(10000)[:350]\n",
    "test_dataset = torch.utils.data.Subset(torchvision.datasets.FashionMNIST(\n",
    "        root='./data', train=False, download=True, \n",
    "        transform=transforms.Compose(preprocess_transforms)\n",
    "    ),\n",
    "    test_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "78dce5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [16, 32, 64]\n",
    "num_epochs = [5, 10, 20]\n",
    "learning_rates = [1e-3, 1e-4]\n",
    "dropouts = [0.0, 0.2]\n",
    "\n",
    "optimizers = {'SGD': optim.SGD, 'Adam': optim.Adam, 'RMSprop': optim.RMSprop}\n",
    "\n",
    "def get_data_loader(batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "59aa4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(dropout=0.0, depth=3, h=64):\n",
    "    layers = []\n",
    "    width, height, dim = 28, 28, 1\n",
    "\n",
    "    for i in range(depth):\n",
    "        in_ch = 16 * (2 ** (i - 1)) if i > 0 else dim\n",
    "        out_ch = 16 * (2 ** i)\n",
    "\n",
    "        layers.append(nn.Conv2d(in_ch, out_ch, 3, padding='same'))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.MaxPool2d(3))\n",
    "\n",
    "    if dropout > 0:\n",
    "        layers.append(nn.Dropout2d(dropout))\n",
    "\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.LazyLinear(h))\n",
    "    layers.append(nn.ReLU())\n",
    "\n",
    "    layers.append(nn.Linear(h, 10))\n",
    "    layers.append(nn.Softmax())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb60d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_size, optimizer_name, lr, dropout, max_epochs=50, verbose=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_loader, test_loader = get_data_loader(batch_size)\n",
    "    model = create_cnn(dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizers[optimizer_name](model.parameters(), lr=lr)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    min_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        correct, total = 0, 0\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "        train_acc = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                running_loss += loss.item()\n",
    "        test_acc = correct / total\n",
    "        test_loss = running_loss / len(test_loader)\n",
    "\n",
    "        history.append((train_acc, train_loss, test_acc, test_loss))\n",
    "        if verbose:\n",
    "            print(f\"{epoch + 1}: Train Acc {train_acc} Train Loss {train_loss} Test Acc {test_acc} Test Loss {test_loss}\")\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "\n",
    "    return best_acc, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a9b70ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.1371\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.4257\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.4543\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.1000\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.4400\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.4029\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.0829\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.2714\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.2457\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.0829\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.2943\n",
      "Batch: 16, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.2457\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.1514\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.5629\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.5514\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.1800\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.5143\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.4571\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.0800\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.3943\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.3714\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.1000\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.3771\n",
      "Batch: 16, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.2943\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.0857\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.6629\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.6400\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.0943\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.6143\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.6514\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.0714\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.4800\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.3971\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.1257\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.3486\n",
      "Batch: 16, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.3743\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.0771\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.4714\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.4743\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.0829\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.4000\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.3600\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.0829\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.1829\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.2257\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.0971\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.1829\n",
      "Batch: 32, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.2800\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.1086\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.6143\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.5686\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.1257\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.5629\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.5314\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.1000\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.2886\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.3343\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.1000\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.2314\n",
      "Batch: 32, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.2286\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.1000\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.5686\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.5686\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.1000\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.6171\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.6514\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.1371\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.4000\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.4714\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.1257\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.4086\n",
      "Batch: 32, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.3086\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.0914\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.3829\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.4743\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.0829\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.3886\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.3629\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.0857\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.1971\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.2486\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.0829\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.2429\n",
      "Batch: 64, Epochs: 5, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.2400\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.0829\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.5371\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.4686\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.0914\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.5029\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.4629\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.0943\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.2857\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.2857\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.0914\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.1886\n",
      "Batch: 64, Epochs: 10, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.2914\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: SGD Acc: 0.0829\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: Adam Acc: 0.6800\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.001, Dropout: 0.0, Opt: RMSprop Acc: 0.5600\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: SGD Acc: 0.0829\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: Adam Acc: 0.6571\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.001, Dropout: 0.2, Opt: RMSprop Acc: 0.5457\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: SGD Acc: 0.0857\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: Adam Acc: 0.3771\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.0001, Dropout: 0.0, Opt: RMSprop Acc: 0.3686\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: SGD Acc: 0.0857\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: Adam Acc: 0.3286\n",
      "Batch: 64, Epochs: 20, Learning rate: 0.0001, Dropout: 0.2, Opt: RMSprop Acc: 0.3171\n"
     ]
    }
   ],
   "source": [
    "param_grid = product(batch_sizes, num_epochs, learning_rates, dropouts, optimizers.keys())\n",
    "results = []\n",
    "\n",
    "for batch_size, epochs, lr, dropout, optimizer_name in param_grid:\n",
    "    best_acc, history = train_and_evaluate(batch_size, optimizer_name, lr, dropout, max_epochs=epochs)\n",
    "    res = (batch_size, epochs, lr, dropout, optimizer_name, best_acc, history)\n",
    "    print(f\"Batch: {res[0]}, Epochs: {res[1]}, Learning rate: {res[2]}, Dropout: {res[3]}, Opt: {res[4]} Acc: {res[5]:.4f}\")\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2e5e4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['Batch', 'Epochs', 'Learning rate', 'Dropout', 'Opt', 'Acc', 'History'])\n",
    "df.to_csv('data/c_5_lab_2_out.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
