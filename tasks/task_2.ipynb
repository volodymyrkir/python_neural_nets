{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T15:11:16.477758309Z",
     "start_time": "2023-10-27T15:11:16.430380321Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ACTIVATION = 'relu'\n",
    "SEED_VALUE = 42\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T15:11:16.642649632Z",
     "start_time": "2023-10-27T15:11:16.477623131Z"
    }
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T15:11:16.686555731Z",
     "start_time": "2023-10-27T15:11:16.644222415Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T15:11:16.687005879Z",
     "start_time": "2023-10-27T15:11:16.686149215Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    return models.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)), \n",
    "        layers.Dense(128, activation=ACTIVATION), \n",
    "        layers.Dense(64, activation=ACTIVATION),   \n",
    "        layers.Dense(NUM_CLASSES)                      \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T15:11:16.687148687Z",
     "start_time": "2023-10-27T15:11:16.686374009Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    ax[0].plot(history.history['accuracy'], label='accuracy')\n",
    "    ax[0].plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].set_ylim([0, 1])\n",
    "\n",
    "    ax[1].plot(history.history['precision'], label='precision')\n",
    "    ax[1].plot(history.history['val_precision'], label='val_precision')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Precision')\n",
    "    ax[1].set_ylim([0, 1])\n",
    "\n",
    "    ax[2].plot(history.history['recall'], label='recall')\n",
    "    ax[2].plot(history.history['val_recall'], label='recall')\n",
    "    ax[2].set_xlabel('Epoch')\n",
    "    ax[2].set_ylabel('Recall')\n",
    "    ax[2].set_ylim([0, 1])\n",
    "\n",
    "    history.history['f1_score'] = (2 * np.array(history.history['precision']) * np.array(history.history['recall']) /\n",
    "                                    (np.array(history.history['precision']) + np.array(history.history['recall']))).tolist()\n",
    "\n",
    "    history.history['val_f1_score'] = (2 * np.array(history.history['val_precision']) * np.array(history.history['val_recall']) /\n",
    "                                    (np.array(history.history['val_precision']) + np.array(history.history['val_recall']))).tolist()\n",
    "\n",
    "    ax[3].plot(history.history['f1_score'], label='f1_score')\n",
    "    ax[3].plot(history.history['val_f1_score'], label='val_f1_score')\n",
    "    ax[3].set_xlabel('Epoch')\n",
    "    ax[3].set_ylabel('F1Score')\n",
    "    ax[3].set_ylim([0, 1])\n",
    "\n",
    "    ax[4].plot(history.history['loss'], label='accuracy')\n",
    "    ax[4].plot(history.history['val_loss'], label='val_accuracy')\n",
    "    ax[4].set_xlabel('Epoch')\n",
    "    ax[4].set_ylabel('Loss')\n",
    "    ax[4].set_ylim([0, 3])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T15:11:16.687242461Z",
     "start_time": "2023-10-27T15:11:16.686492493Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_prec_score(y_true, y_pred):\n",
    "    y_true=y_true.numpy()\n",
    "    y_pred=y_pred.numpy()\n",
    "    y_pred=np.argmax(y_pred, axis=-1)\n",
    "    return precision_score(y_true, y_pred,average='macro')\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = tf.reduce_sum(tf.cast(tf.math.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 1)), tf.float32))\n",
    "    actual_positives = tf.reduce_sum(tf.cast(tf.equal(y_true, 1), tf.float32))\n",
    "    return true_positives / (actual_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_value = precision(y_true, y_pred)\n",
    "    recall_value = recall(y_true, y_pred)\n",
    "    return 2 * ((precision_value * recall_value) / (precision_value + recall_value + tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T15:11:16.687621693Z",
     "start_time": "2023-10-27T15:11:16.686800092Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, optimizer):\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    print(f'\\nTesting: {optimizer}')\n",
    "    history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels), verbose=False)\n",
    "    \n",
    "    reached_90 = next((i + 1 for i, e in enumerate(history.history[\"val_accuracy\"]) if e >= 0.9), np.inf) \n",
    "\n",
    "    if reached_90 == np.inf:\n",
    "        print('\\nNever reached 90% accuracy')\n",
    "    else:\n",
    "        print(f'\\nReached 90% accuracy in {reached_90} epochs')\n",
    "\n",
    "    \n",
    "    results = model.predict(test_images)\n",
    "    \n",
    "    print(metrics.classification_report(np.argmax(results, axis=-1), test_labels))\n",
    "\n",
    "    return (history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T15:13:13.368078321Z",
     "start_time": "2023-10-27T15:11:16.687072109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: SGD\n",
      "\n",
      "Never reached 90% accuracy\n",
      "313/313 [==============================] - 0s 866us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.11      0.20     10000\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11     10000\n",
      "   macro avg       0.10      0.01      0.02     10000\n",
      "weighted avg       1.00      0.11      0.20     10000\n",
      "\n",
      "Testing: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volodymyr/.local/share/virtualenvs/python_neural_nets-VlmVW8YE/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/volodymyr/.local/share/virtualenvs/python_neural_nets-VlmVW8YE/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/volodymyr/.local/share/virtualenvs/python_neural_nets-VlmVW8YE/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached 90% accuracy in 1 epochs\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       977\n",
      "           1       0.99      0.99      0.99      1134\n",
      "           2       0.97      0.97      0.97      1036\n",
      "           3       0.98      0.95      0.97      1035\n",
      "           4       0.97      0.98      0.97       973\n",
      "           5       0.97      0.95      0.96       903\n",
      "           6       0.96      0.99      0.98       933\n",
      "           7       0.96      0.98      0.97      1003\n",
      "           8       0.96      0.95      0.96       981\n",
      "           9       0.97      0.96      0.97      1025\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "\n",
      "Testing: RMSprop\n",
      "\n",
      "Reached 90% accuracy in 1 epochs\n",
      "313/313 [==============================] - 0s 922us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       913\n",
      "           1       0.96      0.99      0.98      1101\n",
      "           2       0.92      0.95      0.94      1000\n",
      "           3       0.84      0.99      0.91       851\n",
      "           4       0.92      0.97      0.94       936\n",
      "           5       0.81      0.99      0.89       724\n",
      "           6       0.97      0.96      0.97       971\n",
      "           7       0.93      0.96      0.95       993\n",
      "           8       0.66      0.98      0.79       660\n",
      "           9       0.97      0.53      0.68      1851\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.93      0.90     10000\n",
      "weighted avg       0.91      0.89      0.88     10000\n",
      "\n",
      "\n",
      "Testing: Adagrad\n",
      "\n",
      "Never reached 90% accuracy\n",
      "313/313 [==============================] - 0s 833us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      1016\n",
      "           1       0.96      0.96      0.96      1142\n",
      "           2       0.89      0.90      0.89      1025\n",
      "           3       0.87      0.87      0.87      1018\n",
      "           4       0.89      0.88      0.89       997\n",
      "           5       0.85      0.86      0.85       881\n",
      "           6       0.91      0.92      0.91       949\n",
      "           7       0.90      0.91      0.90      1015\n",
      "           8       0.84      0.86      0.85       952\n",
      "           9       0.86      0.86      0.86      1005\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n"
     ]
    }
   ],
   "source": [
    "optimizers = ['SGD', 'Adam', 'RMSprop', 'Adagrad']\n",
    "nn_models = {}\n",
    "training_results = {}\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    model = build_model()\n",
    "    nn_models[optimizer] = model\n",
    "\n",
    "    training_results[optimizer] = test_model(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In our investigation we`ve compared 4 optimizers - Adam, SGD, RMSprop and Adagard.\n",
    "Ranking from the worst to the best optimizer based on accuracy, we have \n",
    "1) Stochastic Gradient Descend, which shows minimal performance, having 0.11 accuracy.\n",
    "    SGD is considered one of the simplest optimizers, which may be good for really large data sets, as it uses only subset of validation data for weight-tuning. We also did not consider learning rate parameter, which value may be crucial to SGD`s performance\n",
    "2) Adagard - "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T15:13:13.372839056Z",
     "start_time": "2023-10-27T15:13:13.366666536Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anns3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
