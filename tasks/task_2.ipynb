{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:55:16.911562223Z",
     "start_time": "2023-10-27T12:55:16.855621634Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:52:47.818136906Z",
     "start_time": "2023-10-27T12:52:47.622893425Z"
    }
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:52:47.827964092Z",
     "start_time": "2023-10-27T12:52:47.820491657Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:52:47.828588486Z",
     "start_time": "2023-10-27T12:52:47.825544131Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    return models.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)), \n",
    "        layers.Dense(128, activation='relu'), \n",
    "        layers.Dense(64, activation='relu'),   \n",
    "        layers.Dense(10)                      \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:52:47.883256174Z",
     "start_time": "2023-10-27T12:52:47.828987744Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    ax[0].plot(history.history['accuracy'], label='accuracy')\n",
    "    ax[0].plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].set_ylim([0, 1])\n",
    "\n",
    "    ax[1].plot(history.history['precision'], label='precision')\n",
    "    ax[1].plot(history.history['val_precision'], label='val_precision')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Precision')\n",
    "    ax[1].set_ylim([0, 1])\n",
    "\n",
    "    ax[2].plot(history.history['recall'], label='recall')\n",
    "    ax[2].plot(history.history['val_recall'], label='recall')\n",
    "    ax[2].set_xlabel('Epoch')\n",
    "    ax[2].set_ylabel('Recall')\n",
    "    ax[2].set_ylim([0, 1])\n",
    "\n",
    "    history.history['f1_score'] = (2 * np.array(history.history['precision']) * np.array(history.history['recall']) /\n",
    "                                    (np.array(history.history['precision']) + np.array(history.history['recall']))).tolist()\n",
    "\n",
    "    history.history['val_f1_score'] = (2 * np.array(history.history['val_precision']) * np.array(history.history['val_recall']) /\n",
    "                                    (np.array(history.history['val_precision']) + np.array(history.history['val_recall']))).tolist()\n",
    "\n",
    "    ax[3].plot(history.history['f1_score'], label='f1_score')\n",
    "    ax[3].plot(history.history['val_f1_score'], label='val_f1_score')\n",
    "    ax[3].set_xlabel('Epoch')\n",
    "    ax[3].set_ylabel('F1Score')\n",
    "    ax[3].set_ylim([0, 1])\n",
    "\n",
    "    ax[4].plot(history.history['loss'], label='accuracy')\n",
    "    ax[4].plot(history.history['val_loss'], label='val_accuracy')\n",
    "    ax[4].set_xlabel('Epoch')\n",
    "    ax[4].set_ylabel('Loss')\n",
    "    ax[4].set_ylim([0, 3])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:52:47.883645393Z",
     "start_time": "2023-10-27T12:52:47.883087890Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_prec_score(y_true, y_pred):\n",
    "    y_true=y_true.numpy()\n",
    "    y_pred=y_pred.numpy()\n",
    "    y_pred=np.argmax(y_pred, axis=-1)\n",
    "    return precision_score(y_true, y_pred,average='macro')\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = tf.reduce_sum(tf.cast(tf.math.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 1)), tf.float32))\n",
    "    actual_positives = tf.reduce_sum(tf.cast(tf.equal(y_true, 1), tf.float32))\n",
    "    return true_positives / (actual_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_value = precision(y_true, y_pred)\n",
    "    recall_value = recall(y_true, y_pred)\n",
    "    return 2 * ((precision_value * recall_value) / (precision_value + recall_value + tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:59:42.794989225Z",
     "start_time": "2023-10-27T12:59:42.749365448Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, optimizer):\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\n",
    "                  'accuracy', \n",
    "                  precision,\n",
    "                  recall, \n",
    "                  f1_score,\n",
    "                ])\n",
    "    \n",
    "    print(f'\\nTesting: {optimizer}')\n",
    "    history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels), verbose=False)\n",
    "    \n",
    "    reached_90 = next((i + 1 for i, e in enumerate(history.history[\"val_accuracy\"]) if e >= 0.9), np.inf) \n",
    "\n",
    "    if reached_90 == np.inf:\n",
    "        print('\\nNever reached 90% accuracy')\n",
    "    else:\n",
    "        print(f'\\nReached 90% accuracy in {reached_90} epochs')\n",
    "\n",
    "    \n",
    "    results = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    print(f'\\nTest accuracy: {results[1]}, Test loss: {results[0]}')\n",
    "\n",
    "    plot_history(history)\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "    return (history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T13:01:33.240160901Z",
     "start_time": "2023-10-27T12:59:45.448822599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: SGD\n",
      "\n",
      "Never reached 90% accuracy\n",
      "313/313 [==============================] - 0s 848us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.11      1.00      0.20      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.11     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.11      0.02     10000\n",
      "\n",
      "\n",
      "Testing: Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volodymyr/.local/share/virtualenvs/python_neural_nets-VlmVW8YE/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/volodymyr/.local/share/virtualenvs/python_neural_nets-VlmVW8YE/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/volodymyr/.local/share/virtualenvs/python_neural_nets-VlmVW8YE/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached 90% accuracy in 1 epochs\n",
      "313/313 [==============================] - 0s 850us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.98      0.99      1135\n",
      "           2       0.99      0.94      0.97      1032\n",
      "           3       0.94      0.98      0.96      1010\n",
      "           4       0.98      0.96      0.97       982\n",
      "           5       0.97      0.96      0.97       892\n",
      "           6       0.97      0.98      0.97       958\n",
      "           7       0.98      0.96      0.97      1028\n",
      "           8       0.90      0.98      0.94       974\n",
      "           9       0.99      0.95      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "\n",
      "Testing: RMSprop\n",
      "\n",
      "Reached 90% accuracy in 1 epochs\n",
      "313/313 [==============================] - 0s 941us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       980\n",
      "           1       0.99      0.95      0.97      1135\n",
      "           2       0.98      0.90      0.94      1032\n",
      "           3       0.93      0.95      0.94      1010\n",
      "           4       0.99      0.91      0.95       982\n",
      "           5       0.99      0.87      0.93       892\n",
      "           6       0.99      0.96      0.97       958\n",
      "           7       0.94      0.97      0.96      1028\n",
      "           8       0.70      0.98      0.81       974\n",
      "           9       0.96      0.92      0.94      1009\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.95      0.93      0.94     10000\n",
      "weighted avg       0.95      0.94      0.94     10000\n",
      "\n",
      "\n",
      "Testing: Adagrad\n",
      "\n",
      "Never reached 90% accuracy\n",
      "313/313 [==============================] - 0s 920us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       980\n",
      "           1       0.96      0.97      0.97      1135\n",
      "           2       0.89      0.88      0.88      1032\n",
      "           3       0.87      0.87      0.87      1010\n",
      "           4       0.90      0.88      0.89       982\n",
      "           5       0.88      0.85      0.87       892\n",
      "           6       0.92      0.93      0.93       958\n",
      "           7       0.90      0.89      0.89      1028\n",
      "           8       0.85      0.85      0.85       974\n",
      "           9       0.85      0.87      0.86      1009\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n"
     ]
    }
   ],
   "source": [
    "optimizers = ['SGD', 'Adam', 'RMSprop', 'Adagrad']\n",
    "nn_models = {}\n",
    "training_results = {}\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    model = build_model()\n",
    "    nn_models[optimizer] = model\n",
    "\n",
    "    training_results[optimizer] = test_model(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T12:53:10.538241698Z",
     "start_time": "2023-10-27T12:53:10.534057565Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anns3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
